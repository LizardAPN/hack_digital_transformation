{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2f11dabb",
   "metadata": {},
   "source": [
    "# Подготовка ноутбука "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85f07fbd",
   "metadata": {},
   "source": [
    "## Пробрасываем magic methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "97feaebc",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%reload_ext autoreload"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5324521",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cd10fe31",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np \n",
    "from data.prepare_data import PrepareData\n",
    "from dotenv import load_dotenv\n",
    "import os \n",
    "from pathlib import Path\n",
    "from warnings import filterwarnings \n",
    "import torch \n",
    "import torchvision\n",
    "from torch.utils.data import DataLoader\n",
    "from IPython.display import display\n",
    "import pytesseract\n",
    "import shutil\n",
    "try:\n",
    "    from PIL import Image\n",
    "except ImportError:\n",
    "     import Image\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f5e2582",
   "metadata": {},
   "source": [
    "## Нужные переменные "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e7ef1558",
   "metadata": {},
   "outputs": [],
   "source": [
    "ROOT_DIR = Path('../../')\n",
    "load_dotenv()\n",
    "filterwarnings(action='ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6dee36be",
   "metadata": {},
   "source": [
    "# Загрузка датафрейма"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "83595150",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Отсутствуют необходимые столбцы: ['Имя файла', 'latitude', 'longitude']",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[4]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# Создание датасета с автоматическим разделением\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m dataset = \u001b[43mPrepareData\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m      3\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcsv_path\u001b[49m\u001b[43m=\u001b[49m\u001b[43mROOT_DIR\u001b[49m\u001b[43m \u001b[49m\u001b[43m/\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mdata/processed_data/merged_data.csv\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m      4\u001b[39m \u001b[43m    \u001b[49m\u001b[43mimages_dir\u001b[49m\u001b[43m=\u001b[49m\u001b[43mROOT_DIR\u001b[49m\u001b[43m \u001b[49m\u001b[43m/\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mdata/raw_data/data/metadata/INC/united_image/\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m      5\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtest_size\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m0.2\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m      6\u001b[39m \u001b[43m    \u001b[49m\u001b[43mrandom_state\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m42\u001b[39;49m\n\u001b[32m      7\u001b[39m \u001b[43m)\u001b[49m\n\u001b[32m      9\u001b[39m \u001b[38;5;66;03m# Получение тренировочного и тестового датасетов\u001b[39;00m\n\u001b[32m     10\u001b[39m train_dataset = dataset.get_train_dataset()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Hack_digital/hack_digital_transformation/src/data/prepare_data.py:70\u001b[39m, in \u001b[36mPrepareData.__init__\u001b[39m\u001b[34m(self, csv_path, images_dir, test_size, random_state)\u001b[39m\n\u001b[32m     67\u001b[39m \u001b[38;5;28mself\u001b[39m.df = pd.read_csv(csv_path)\n\u001b[32m     69\u001b[39m \u001b[38;5;66;03m# Создаем чистый датафрейм только с нужными столбцами\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m70\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_create_clean_dataframe\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     72\u001b[39m \u001b[38;5;66;03m# Фильтруем только существующие файлы\u001b[39;00m\n\u001b[32m     73\u001b[39m \u001b[38;5;28mself\u001b[39m.valid_indices = [\n\u001b[32m     74\u001b[39m     i \u001b[38;5;28;01mfor\u001b[39;00m i, row \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m.df.iterrows() \u001b[38;5;28;01mif\u001b[39;00m os.path.exists(os.path.join(images_dir, row[\u001b[33m\"\u001b[39m\u001b[33mfilename\u001b[39m\u001b[33m\"\u001b[39m]))\n\u001b[32m     75\u001b[39m ]\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Hack_digital/hack_digital_transformation/src/data/prepare_data.py:91\u001b[39m, in \u001b[36mPrepareData._create_clean_dataframe\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m     88\u001b[39m missing_columns = [col \u001b[38;5;28;01mfor\u001b[39;00m col \u001b[38;5;129;01min\u001b[39;00m required_columns \u001b[38;5;28;01mif\u001b[39;00m col \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m.df.columns]\n\u001b[32m     90\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m missing_columns:\n\u001b[32m---> \u001b[39m\u001b[32m91\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mОтсутствуют необходимые столбцы: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmissing_columns\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m     93\u001b[39m \u001b[38;5;66;03m# Создаем новый датафрейм с нужными столбцами\u001b[39;00m\n\u001b[32m     94\u001b[39m clean_df = \u001b[38;5;28mself\u001b[39m.df[required_columns].copy()\n",
      "\u001b[31mValueError\u001b[39m: Отсутствуют необходимые столбцы: ['Имя файла', 'latitude', 'longitude']"
     ]
    }
   ],
   "source": [
    "# Создание датасета с автоматическим разделением\n",
    "dataset = PrepareData(\n",
    "    csv_path=ROOT_DIR / \"data/processed_data/merged_data.csv\",\n",
    "    images_dir=ROOT_DIR / \"data/raw_data/data/metadata/INC/united_image/\",\n",
    "    test_size=0.2,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# Получение тренировочного и тестового датасетов\n",
    "train_dataset = dataset.get_train_dataset()\n",
    "test_dataset = dataset.get_test_dataset()\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)\n",
    "\n",
    "# Пример использования\n",
    "for images, coordinates in train_loader:\n",
    "    print(f\"Тренировочный батч: images {images.shape}, coordinates {len(coordinates)}\")\n",
    "    break\n",
    "\n",
    "for images, coordinates in test_loader:\n",
    "    print(f\"Тестовый батч: images {images.shape}, coordinates {len(coordinates)}\")\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fb26062",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import easyocr\n",
    "import re\n",
    "from typing import List, Tuple, Optional\n",
    "\n",
    "class OverlayOCR:\n",
    "    WHITELIST_RE = re.compile(r\"[A-Za-z0-9_]+\")\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        langs: Optional[List[str]] = None,\n",
    "        gpu: bool = False,\n",
    "        verbose: bool = False,\n",
    "        gap_mult: float = 1.6,\n",
    "        canvas_size: int = 3600,\n",
    "        mag_ratio: float = 3.0,\n",
    "        add_margin: float = 0.10,\n",
    "        text_threshold: float = 0.55,\n",
    "        low_text: float = 0.30,\n",
    "        link_threshold: float = 0.30,\n",
    "    ):\n",
    "        \"\"\"\n",
    "        langs: языки easyocr, напр. ['en'] или ['en','ru']\n",
    "        gap_mult: чувствительность к горизонтальным разрывам (меньше -> больше '_')\n",
    "        canvas_size/mag_ratio: масштабирование внутри easyocr\n",
    "        \"\"\"\n",
    "        self.langs = langs or ['en']\n",
    "        self.reader = easyocr.Reader(self.langs, gpu=gpu, verbose=verbose)\n",
    "        self.gap_mult = gap_mult\n",
    "        self.canvas_size = canvas_size\n",
    "        self.mag_ratio = mag_ratio\n",
    "        self.add_margin = add_margin\n",
    "        self.text_threshold = text_threshold\n",
    "        self.low_text = low_text\n",
    "        self.link_threshold = link_threshold\n",
    "\n",
    "    # ---------- утилиты ----------\n",
    "    @staticmethod\n",
    "    def _clean_token(t: str) -> str:\n",
    "        return \"\".join(OverlayOCR.WHITELIST_RE.findall(t))\n",
    "\n",
    "    @staticmethod\n",
    "    def _alnum_class(ch: str) -> str:\n",
    "        return 'D' if ch.isdigit() else ('A' if ch.isalpha() else '_')\n",
    "\n",
    "    def _join_with_gaps(self, results, sep='_') -> Tuple[str, float, list]:\n",
    "        \"\"\"\n",
    "        Склейка токенов слева направо:\n",
    "        - '_' если горизонтальный зазор >> медианного,\n",
    "        - '_' на границах A<->D.\n",
    "        \"\"\"\n",
    "        items = []\n",
    "        for bbox, text, conf in results:\n",
    "            t = self._clean_token(text)\n",
    "            if not t:\n",
    "                continue\n",
    "            x0 = min(p[0] for p in bbox); x1 = max(p[0] for p in bbox)\n",
    "            items.append((x0, x1, t, float(conf)))\n",
    "        if not items:\n",
    "            return \"\", 0.0, []\n",
    "\n",
    "        items.sort(key=lambda z: z[0])\n",
    "        gaps = []\n",
    "        for i in range(1, len(items)):\n",
    "            gaps.append(items[i][0] - items[i-1][1])\n",
    "        med_gap = np.median(gaps) if gaps else 0\n",
    "\n",
    "        out = []\n",
    "        confs = []\n",
    "        prev = None\n",
    "        for i, (x0, x1, t, c) in enumerate(items):\n",
    "            if prev is not None:\n",
    "                gap = x0 - prev[1]\n",
    "                need_sep = (med_gap > 0 and gap > self.gap_mult * med_gap)\n",
    "                # буква↔️цифра – полезно отделить\n",
    "                if not need_sep:\n",
    "                    prev_last = out[-1][-1] if out else ''\n",
    "                    if prev_last and t:\n",
    "                        need_sep = (self._alnum_class(prev_last) != self._alnum_class(t[0]))\n",
    "                if need_sep and (not out or out[-1] != sep):\n",
    "                    out.append(sep)\n",
    "            out.append(t)\n",
    "            confs.append(c)\n",
    "            prev = (x0, x1)\n",
    "\n",
    "        text = \"\".join(out)\n",
    "        text = re.sub(r\"_+\", \"_\", text).strip(\"_\")\n",
    "        avg_conf = float(sum(confs)/len(confs)) if confs else 0.0\n",
    "        return text, avg_conf, items\n",
    "\n",
    "    @staticmethod\n",
    "    def _normalize_overlays(s: str) -> str:\n",
    "        \"\"\"Правки под формат MMC_hd_... и расстановка подчёркиваний.\"\"\"\n",
    "        s = re.sub(r\"^MMC(?:_)?h(?:d)?\", \"MMC_hd\", s, flags=re.IGNORECASE)\n",
    "        s = re.sub(r\"^MMC_?hd_?\", \"MMC_hd_\", s, flags=re.IGNORECASE)\n",
    "        s = re.sub(r\"([A-Za-z])([0-9])\", r\"\\1_\\2\", s)\n",
    "        s = re.sub(r\"([0-9])([A-Za-z])\", r\"\\1_\\2\", s)\n",
    "        s = re.sub(r\"_+\", \"_\", s).strip(\"_\")\n",
    "        return s\n",
    "\n",
    "    @staticmethod\n",
    "    def _snap_digits_tail(s: str) -> str:\n",
    "        \"\"\"\n",
    "        Если хвост цифр склеен, режем на 4-1-1 (типичный случай).\n",
    "        Пример: ...229221 -> ...2292_2_1\n",
    "        \"\"\"\n",
    "        m = re.search(r\"^(.*?)(\\d{6,})$\", s)\n",
    "        if not m:\n",
    "            return s\n",
    "        head, digits = m.group(1), m.group(2)\n",
    "        if len(digits) >= 6:\n",
    "            s = f\"{head}{digits[:4]}_{digits[4:5]}_{digits[5:]}\"\n",
    "        return re.sub(r\"_+\", \"_\", s).strip(\"_\")\n",
    "\n",
    "\n",
    "    # ---------- EasyOCR запуск на ROI ----------\n",
    "    def run_on_roi(self, roi_bgr) -> Tuple[str, str, str, float]:\n",
    "        params = dict(\n",
    "            decoder='greedy',\n",
    "            detail=1,\n",
    "            paragraph=False,\n",
    "            contrast_ths=0.05,\n",
    "            adjust_contrast=0.7,\n",
    "            text_threshold=self.text_threshold,\n",
    "            low_text=self.low_text,\n",
    "            link_threshold=self.link_threshold,\n",
    "            canvas_size=self.canvas_size,\n",
    "            mag_ratio=self.mag_ratio,\n",
    "            add_margin=self.add_margin,\n",
    "        )\n",
    "        results = self.reader.readtext(roi_bgr, **params)\n",
    "        joined, conf, _ = self._join_with_gaps(results, sep=\"_\")\n",
    "        norm = self._normalize_overlays(joined)\n",
    "        final = self._snap_digits_tail(norm)\n",
    "        final = re.sub(r\"^MMC_?hd_?\", \"MMC_hd_\", final, flags=re.IGNORECASE)\n",
    "        final = re.sub(r\"_+\", \"_\", final).strip(\"_\")\n",
    "        return joined, norm, final, conf\n",
    "\n",
    "    # ---------- ROI генераторы ----------\n",
    "    @staticmethod\n",
    "    def roi_left_bottom(img, w_frac=1/3, h_frac=1/4):\n",
    "        H, W = img.shape[:2]\n",
    "        return img[H - int(H*h_frac):H, 0:int(W*w_frac)]\n",
    "\n",
    "    @staticmethod\n",
    "    def roi_bottom_band(img, h_frac=1/3):\n",
    "        H, _ = img.shape[:2]\n",
    "        y0 = H - int(H*h_frac)\n",
    "        return img[y0:H, :]\n",
    "\n",
    "    @staticmethod\n",
    "    def roi_auto_band(img):\n",
    "        g = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "        _, b = cv2.threshold(cv2.GaussianBlur(g, (5,5), 0), 0, 255,\n",
    "                             cv2.THRESH_BINARY_INV + cv2.THRESH_OTSU)\n",
    "        row = (b > 0).sum(axis=1).astype(np.float32)\n",
    "        k = max(3, (img.shape[0]//100)*2+1)\n",
    "        row = cv2.GaussianBlur(row.reshape(-1,1),(1,k),0).ravel()\n",
    "        start = img.shape[0]//2\n",
    "        idx = start + int(np.argmax(row[start:]))\n",
    "        band_half = max(img.shape[0]//12, 20)\n",
    "        y0, y1 = max(0, idx-band_half), min(img.shape[0], idx+band_half)\n",
    "        return img[y0:y1, :]\n",
    "\n",
    "    # ---------- главный метод ----------\n",
    "    def run_on_image(self, image_path: str) -> Tuple[str, str, str, float, str]:\n",
    "        \"\"\"\n",
    "        Возвращает:\n",
    "          final, norm, joined, conf, best_roi_name\n",
    "        \"\"\"\n",
    "        img = cv2.imread(image_path)\n",
    "        assert img is not None, f\"Не удалось загрузить изображение: {image_path}\"\n",
    "\n",
    "        rois = [\n",
    "            (\"left_bottom\", self.roi_left_bottom(img, 1/3, 1/4)),\n",
    "            (\"bottom_band\", self.roi_bottom_band(img, 1/3)),\n",
    "            (\"auto_band\",   self.roi_auto_band(img)),\n",
    "        ]\n",
    "\n",
    "        best = None\n",
    "        best_name = \"\"\n",
    "        best_pack = (\"\", \"\", \"\", 0.0)\n",
    "\n",
    "        for name, roi in rois:\n",
    "            joined, norm, final, conf = self.run_on_roi(roi)\n",
    "            cand = (conf, len(final), (final, norm, joined, conf), name)\n",
    "            if (best is None) or (cand > best):\n",
    "                best = cand\n",
    "                best_pack = (final, norm, joined, conf)\n",
    "                best_name = name\n",
    "\n",
    "        final, norm, joined, conf = best_pack\n",
    "        return final, norm, joined, conf, best_name\n",
    "\n",
    "\n",
    "# ===================== пример использования =====================\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    IMG = r'/home/lizardapn/Hack_digital/hack_digital_transformation/data/raw_data/data/metadata/INC/19-001_gin_garbage_echd_19.08.25/ffccf36c-075a-43d9-8570-a01f3afcaf76.jpg'\n",
    "\n",
    "    ocr = OverlayOCR(\n",
    "        langs=['en'],          # ['en','ru'] если нужна кириллица\n",
    "        gpu=True,\n",
    "        gap_mult=1.6,\n",
    "        canvas_size=3600,\n",
    "        mag_ratio=3.0,\n",
    "        add_margin=0.10,\n",
    "        text_threshold=0.55,\n",
    "        low_text=0.30,\n",
    "        link_threshold=0.30,\n",
    "    )\n",
    "\n",
    "    final, norm, joined, conf, roi_name = ocr.run_on_image(IMG)\n",
    "    print(f\"Best ROI: {roi_name} | conf={conf:.2f}\")\n",
    "    print(\"joined:\", joined)\n",
    "    print(\"norm  :\", norm)\n",
    "    print(\"final :\", final)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hack_digital_transformation",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
