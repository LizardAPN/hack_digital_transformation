# SQL Скрипты

Эта директория содержит SQL скрипты, используемые в ML проекте для процессов извлечения, преобразования и загрузки данных (ETL).

## Назначение

SQL скрипты в этой директории служат нескольким целям:

1. **Извлечение данных**: Запросы для извлечения данных из различных источников (базы данных, хранилища данных)
2. **Преобразование данных**: Скрипты для очистки, преобразования и подготовки данных для ML пайплайнов
3. **Инжиниринг признаков**: Создание признаков и агрегация на основе SQL
4. **Валидация данных**: Запросы для проверки качества и целостности данных
5. **Отчетность**: Ад-хок запросы для разведочного анализа данных и отчетности

## Соглашение об именовании файлов

Следуйте этому соглашению об именовании для SQL скриптов:

```
[порядок]_[описание].[расширение]
```

Примеры:
- `01_extract_raw_data.sql` - Извлечение сырых данных из источников
- `02_clean_customer_data.sql` - Очистка и предобработка данных клиентов
- `03_create_features.sql` - Создание признаков
- `99_data_validation.sql` - Финальные проверки качества данных

## Структура скрипта

Каждый SQL скрипт должен следовать этой структуре:

```sql
-- =============================================
-- Скрипт: [Краткое описание того, что делает скрипт]
-- Автор: [Имя автора]
-- Дата: [Дата создания/модификации]
-- =============================================

/* 
Описание:
[Краткое описание назначения скрипта]

Входные данные:
[Список входных таблиц или источников данных]

Выходные данные:
[Список выходных таблиц или результирующих наборов]

Зависимости:
[Список зависимостей или допущений]
*/

-- Установка параметров сессии (если необходимо)
SET statement_timeout = 0;

-- Основная логика запроса
[SQL код здесь]

-- Пример использования (если применимо)
/*
SELECT * FROM output_table LIMIT 10;
*/
```

## Лучшие практики

### 1. Документация
- Включайте заголовочный комментарий с объяснением назначения скрипта
- Документируйте спецификации входных и выходных данных
- Добавляйте inline комментарии для сложной логики

### 2. Обработка ошибок
- Включайте проверки валидации где это уместно
- Используйте транзакции для многошаговых операций
- Явно обрабатывайте NULL значения

### 3. Производительность
- Используйте подходящие индексы
- Избегайте SELECT * в продакшен скриптах
- Ограничивайте размеры результирующих наборов во время разработки
- Используйте EXPLAIN для анализа планов запросов

### 4. Безопасность
- Параметризуйте запросы когда это возможно
- Избегайте хардкодинга чувствительной информации
- Следуйте принципу минимальных привилегий для подключений к базам данных

### 5. Контроль версий
- Коммитьте скрипты в систему контроля версий
- Используйте осмысленные сообщения коммитов
- Помечайте релизы когда это уместно

## Общие типы скриптов

### Скрипты извлечения данных
```sql
-- Извлечение данных из источника
SELECT 
    customer_id,
    purchase_date,
    amount,
    product_category
FROM source_system.sales
WHERE purchase_date >= '2023-01-01'
  AND purchase_date < '2024-01-01';
```

### Скрипты преобразования данных
```sql
-- Очистка и преобразование данных
CREATE TABLE cleaned_data AS
SELECT 
    customer_id,
    DATE_TRUNC('month', purchase_date) AS purchase_month,
    SUM(amount) AS total_spent,
    COUNT(*) AS transaction_count
FROM raw_sales
WHERE amount > 0  -- Удаление недействительных транзакций
GROUP BY customer_id, DATE_TRUNC('month', purchase_date);
```

### Скрипты инжиниринга признаков
```sql
-- Создание признаков для ML моделей
CREATE TABLE customer_features AS
SELECT 
    customer_id,
    AVG(total_spent) AS avg_monthly_spending,
    MAX(transaction_count) AS max_transactions_per_month,
    COUNT(DISTINCT purchase_month) AS active_months,
    CASE 
        WHEN COUNT(DISTINCT purchase_month) >= 10 THEN 'high_frequency'
        WHEN COUNT(DISTINCT purchase_month) >= 5 THEN 'medium_frequency'
        ELSE 'low_frequency'
    END AS frequency_segment
FROM cleaned_data
GROUP BY customer_id;
```

## Интеграция с ML пайплайном

Эти SQL скрипты могут быть интегрированы с ML пайплайном несколькими способами:

1. **Прямое выполнение**: Запуск скриптов как части рабочих процессов подготовки данных
2. **Коннекторы к базам данных**: Использование Python коннекторов к базам данных для выполнения запросов
3. **ETL инструменты**: Интеграция с такими инструментами как Apache Airflow, dbt или пользовательскими ETL пайплайнами

Пример интеграции на Python:
```python
import psycopg2
import pandas as pd

def execute_sql_script(script_path, connection_params):
    """Выполнение SQL скрипта и возврат результатов в виде DataFrame"""
    with open(script_path, 'r') as file:
        query = file.read()
    
    conn = psycopg2.connect(**connection_params)
    df = pd.read_sql_query(query, conn)
    conn.close()
    return df
```

## Тестирование SQL скриптов

1. **Модульное тестирование**: Тестирование отдельных запросов с известными входными данными и ожидаемыми результатами
2. **Интеграционное тестирование**: Проверка корректности работы скриптов с реальными подключениями к базам данных
3. **Тестирование производительности**: Мониторинг времени выполнения запросов и использования ресурсов
4. **Тестирование качества данных**: Валидация соответствия выходных данных требованиям качества

## Зависимости

Убедитесь, что все необходимые драйверы или коннекторы к базам данных включены в зависимости проекта:
- PostgreSQL: `psycopg2`
- MySQL: `mysql-connector-python`
- SQL Server: `pyodbc`
- SQLite: Встроенный в Python

Обновите `pyproject.toml` при добавлении новых зависимостей баз данных:
```toml
[project.dependencies]
# ... существующие зависимости ...
psycopg2 = "^2.9.0"  # Для PostgreSQL
